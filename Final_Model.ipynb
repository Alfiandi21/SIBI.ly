{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VRH_EkPfhSfn"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l4Y7PfSOiWmi"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HQVvICpCiX5Q"
      },
      "outputs": [],
      "source": [
        "# Path ke dataset\n",
        "dataset_path = '/content/drive/My Drive/Bangkit/Capstone/Data Mentah/Abjad/SIBI'\n",
        "\n",
        "# Mengatur parameter ImageDataGenerator\n",
        "data_gen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "\n",
        "# Menggunakan data generator untuk memuat data latih dan validasi\n",
        "train_generator = data_gen.flow_from_directory(\n",
        "    dataset_path,\n",
        "    target_size=(64, 64),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "validation_generator = data_gen.flow_from_directory(\n",
        "    dataset_path,\n",
        "    target_size=(64, 64),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fozF-uiri56I"
      },
      "outputs": [],
      "source": [
        "def create_model(input_shape, num_classes):\n",
        "    model = Sequential()\n",
        "    model.add(TimeDistributed(Conv2D(32, (3, 3), activation='relu'), input_shape=input_shape))\n",
        "    model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
        "    model.add(TimeDistributed(Conv2D(64, (3, 3), activation='relu')))\n",
        "    model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
        "    model.add(TimeDistributed(Flatten()))\n",
        "    model.add(LSTM(128))\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "    return model\n",
        "\n",
        "input_shape = (sequence_length, 64, 64, 3)\n",
        "num_classes = 24\n",
        "model = create_model(input_shape, num_classes)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SjRh2Q30jISO"
      },
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
        "    epochs=30\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DhVMqqmWjKcq"
      },
      "outputs": [],
      "source": [
        "loss, accuracy = model.evaluate(validation_generator)\n",
        "print(f'Validation Loss: {loss}')\n",
        "print(f'Validation Accuracy: {accuracy}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_3vHdS-bjNwm"
      },
      "outputs": [],
      "source": [
        "# Menyimpan model ke file .h5\n",
        "model.save('/content/drive/My Drive/Bangkit/Capstone/model_sibi_final.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Higw2WMF_rmZ"
      },
      "outputs": [],
      "source": [
        "# Menyimpan arsitektur model ke dalam file JSON\n",
        "model_json = model.to_json()\n",
        "json_path = '/content/drive/My Drive/Bangkit/Capstone/model_sibi_final.json'\n",
        "with open(json_path, \"w\") as json_file:\n",
        "    json_file.write(model_json)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZoD1XEgM_vf0"
      },
      "outputs": [],
      "source": [
        "# Menyimpan riwayat pelatihan ke dalam file JSON\n",
        "history_path = '/content/drive/My Drive/Bangkit/Capstone/training_history.json'\n",
        "with open(history_path, 'w') as f:\n",
        "    json.dump(history.history, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0y5yYk79jQWD"
      },
      "outputs": [],
      "source": [
        "# Plot training & validation accuracy values\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}